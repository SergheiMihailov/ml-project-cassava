{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgUnOFSuaCfs",
        "outputId": "d7329738-b32a-4826-ff9f-4e056f2d624a"
      },
      "source": [
        "import gdown\n",
        "#!gdown --id \"1NdsNtg7RpTESOKojFbG5vlJMyxbbnNfx\" # images from gdrive\n",
        "!wget files.brainfriz.com/train_images.zip      # secondary link for images\n",
        "!wget files.brainfriz.com/augmented_images.zip  # augmented images\n",
        "!wget files.brainfriz.com/aug_train.csv         # augmented train.csv\n",
        "!wget files.brainfriz.com/full_train.csv        # full train -> augmented + original\n",
        "!gdown --id \"1xbEVK_NigW_5ngwKMHvuOTehYhT2v2WF\" # labels\n",
        "!gdown --id \"1SvI9dN2_25c2OlevwK4TjmzBNysjE_PO\" # label mapping"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-18 11:29:18--  http://files.brainfriz.com/train_images.zip\n",
            "Resolving files.brainfriz.com (files.brainfriz.com)... 138.201.201.196\n",
            "Connecting to files.brainfriz.com (files.brainfriz.com)|138.201.201.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://files.brainfriz.com/train_images.zip [following]\n",
            "--2021-03-18 11:29:19--  https://files.brainfriz.com/train_images.zip\n",
            "Connecting to files.brainfriz.com (files.brainfriz.com)|138.201.201.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2569658627 (2.4G) [application/zip]\n",
            "Saving to: ‘train_images.zip’\n",
            "\n",
            "train_images.zip    100%[===================>]   2.39G  20.1MB/s    in 2m 2s   \n",
            "\n",
            "2021-03-18 11:31:22 (20.0 MB/s) - ‘train_images.zip’ saved [2569658627/2569658627]\n",
            "\n",
            "--2021-03-18 11:31:22--  http://files.brainfriz.com/augmented_images.zip\n",
            "Resolving files.brainfriz.com (files.brainfriz.com)... 138.201.201.196\n",
            "Connecting to files.brainfriz.com (files.brainfriz.com)|138.201.201.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://files.brainfriz.com/augmented_images.zip [following]\n",
            "--2021-03-18 11:31:23--  https://files.brainfriz.com/augmented_images.zip\n",
            "Connecting to files.brainfriz.com (files.brainfriz.com)|138.201.201.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2145363029 (2.0G) [application/zip]\n",
            "Saving to: ‘augmented_images.zip’\n",
            "\n",
            "augmented_images.zi 100%[===================>]   2.00G  20.2MB/s    in 1m 42s  \n",
            "\n",
            "2021-03-18 11:33:05 (20.1 MB/s) - ‘augmented_images.zip’ saved [2145363029/2145363029]\n",
            "\n",
            "--2021-03-18 11:33:06--  http://files.brainfriz.com/aug_train.csv\n",
            "Resolving files.brainfriz.com (files.brainfriz.com)... 138.201.201.196\n",
            "Connecting to files.brainfriz.com (files.brainfriz.com)|138.201.201.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://files.brainfriz.com/aug_train.csv [following]\n",
            "--2021-03-18 11:33:07--  https://files.brainfriz.com/aug_train.csv\n",
            "Connecting to files.brainfriz.com (files.brainfriz.com)|138.201.201.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1487099 (1.4M) [text/csv]\n",
            "Saving to: ‘aug_train.csv’\n",
            "\n",
            "aug_train.csv       100%[===================>]   1.42M  1.94MB/s    in 0.7s    \n",
            "\n",
            "2021-03-18 11:33:08 (1.94 MB/s) - ‘aug_train.csv’ saved [1487099/1487099]\n",
            "\n",
            "--2021-03-18 11:33:08--  http://files.brainfriz.com/full_train.csv\n",
            "Resolving files.brainfriz.com (files.brainfriz.com)... 138.201.201.196\n",
            "Connecting to files.brainfriz.com (files.brainfriz.com)|138.201.201.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://files.brainfriz.com/full_train.csv [following]\n",
            "--2021-03-18 11:33:08--  https://files.brainfriz.com/full_train.csv\n",
            "Connecting to files.brainfriz.com (files.brainfriz.com)|138.201.201.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1590124 (1.5M) [text/csv]\n",
            "Saving to: ‘full_train.csv’\n",
            "\n",
            "full_train.csv      100%[===================>]   1.52M  2.12MB/s    in 0.7s    \n",
            "\n",
            "2021-03-18 11:33:10 (2.12 MB/s) - ‘full_train.csv’ saved [1590124/1590124]\n",
            "\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xbEVK_NigW_5ngwKMHvuOTehYhT2v2WF\n",
            "To: /content/train.csv\n",
            "100% 358k/358k [00:00<00:00, 54.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SvI9dN2_25c2OlevwK4TjmzBNysjE_PO\n",
            "To: /content/label_num_to_disease_map.json\n",
            "100% 172/172 [00:00<00:00, 104kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfe8zvpIaK_y"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/')\n",
        "!unzip -qq -o train_images.zip\n",
        "!unzip -qq -o augmented_images.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cewj2hGxaQhr"
      },
      "source": [
        "import keras\n",
        "import io\n",
        "import json\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import numpy as np\n",
        "import os, shutil\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from collections import Counter"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNZwfyBGEgBP"
      },
      "source": [
        "!mkdir images #for the confusion matrix images\n",
        "\n",
        "# move the training images (aug+original) to the same folder \n",
        "file_names = os.listdir('orig_and_aug_train_images/')\n",
        "for file_name in file_names:\n",
        "    shutil.move(os.path.join('orig_and_aug_train_images', file_name), 'train_images')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo3xBjqfer2V",
        "outputId": "3451b206-7ea0-42c3-8e0a-4bade8e6fd07"
      },
      "source": [
        "data = pd.read_csv('full_train.csv')\n",
        "f = open('label_num_to_disease_map.json')\n",
        "real_labels = json.load(f)\n",
        "real_labels = {int(k):v for k,v in real_labels.items()}\n",
        "data['class_name'] = data.label.map(real_labels)\n",
        "\n",
        "train_path = 'train_images/'\n",
        "train,val = train_test_split(data, test_size = 0.20, random_state = 20, shuffle = True, stratify = data['class_name'])\n",
        "\n",
        "print(\"Training:\", Counter(train['class_name']))\n",
        "print(\"Validation:\", Counter(val['class_name']))\n",
        "\n",
        "IMG_SIZE = 224 #smaller size -> faster training. We have to see if this plays a role though for accuracy\n",
        "SIZE = (IMG_SIZE,IMG_SIZE)\n",
        "N_CLASSES = 5\n",
        "BATCH_SIZE = 128 # Mobilenet 128, resnet: 64(?) Watch out for OOM\n",
        "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "train_datagen = ImageDataGenerator()\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "\n",
        "train_set = train_datagen.flow_from_dataframe(train,\n",
        "                                directory = train_path,\n",
        "                                x_col = 'image_id',\n",
        "                                y_col = 'class_name',\n",
        "                                color_mode='rgb',\n",
        "                                class_mode='categorical',\n",
        "                                target_size = SIZE,\n",
        "                                shuffle = True,\n",
        "                                batch_size = BATCH_SIZE)\n",
        "\n",
        "val_set = test_datagen.flow_from_dataframe(val,\n",
        "                                directory = train_path,\n",
        "                                x_col = 'image_id',\n",
        "                                y_col = 'class_name',\n",
        "                                color_mode='rgb',\n",
        "                                class_mode='categorical',\n",
        "                                target_size = SIZE,\n",
        "                                shuffle = False, #important\n",
        "                                batch_size = BATCH_SIZE)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: Counter({'Cassava Brown Streak Disease (CBSD)': 10527, 'Healthy': 10526, 'Cassava Bacterial Blight (CBB)': 10526, 'Cassava Green Mottle (CGM)': 10526, 'Cassava Mosaic Disease (CMD)': 10526})\n",
            "Validation: Counter({'Cassava Mosaic Disease (CMD)': 2632, 'Cassava Green Mottle (CGM)': 2632, 'Healthy': 2632, 'Cassava Bacterial Blight (CBB)': 2631, 'Cassava Brown Streak Disease (CBSD)': 2631})\n",
            "Found 52631 validated image filenames belonging to 5 classes.\n",
            "Found 13158 validated image filenames belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq5vL_YeHkS4"
      },
      "source": [
        "class ConfusionMatrix(keras.callbacks.Callback):\n",
        "  def __init__(self, val_set, val_y):\n",
        "    self.val_set = val_set\n",
        "    self.val_y = val_y\n",
        "    self.counter = 0\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    self.plot()\n",
        "    self.counter += 1\n",
        "\n",
        "  def plot(self):\n",
        "    test_pred_raw = self.model.predict(self.val_set)\n",
        "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "\n",
        "    cm = sklearn.metrics.confusion_matrix(self.val_y, test_pred)\n",
        "    self.plot_confusion_matrix(cm, class_names=[0,1,2,3,4])\n",
        "\n",
        "  def plot_confusion_matrix(self, cm, class_names):\n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "\n",
        "    labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "    threshold = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "      plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.savefig('images/conf{0}.png'.format(self.counter)) #save file\n",
        "    plt.close()\n",
        "\n",
        "plotter = ConfusionMatrix(val_set, val_set.classes);"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "dYVUjTm_e9jI",
        "outputId": "1b7cc5ee-34c6-4c81-c549-bc67b6a41145"
      },
      "source": [
        "mobileNetV3Small = tf.keras.applications.MobileNetV3Small(\n",
        "    input_shape=INPUT_SHAPE, alpha=1.0, minimalistic=True, include_top=True,\n",
        "    weights=None, input_tensor=None, classes=N_CLASSES, pooling='avg',\n",
        "    dropout_rate=0.2, classifier_activation='softmax'\n",
        ")\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "inputs = tf.keras.applications.mobilenet_v3.preprocess_input(inputs) #only for mobilenet\n",
        "\n",
        "model = tf.keras.Model(inputs, mobileNetV3Small(inputs))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy','categorical_accuracy'])\n",
        "\n",
        "model.fit(\n",
        "        train_set,\n",
        "        steps_per_epoch=train_set.n // BATCH_SIZE,\n",
        "        epochs=40, \n",
        "        callbacks = [plotter]) #callback for confusion matrix per epoch\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "  1/411 [..............................] - ETA: 1:32:18 - loss: 1.6527 - accuracy: 0.1953 - categorical_accuracy: 0.1953"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8d8aacaa545d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         callbacks = [plotter]) #callback for confusion matrix per epoch\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCkuZCplFo0l"
      },
      "source": [
        "from google.colab import files\n",
        "model.save(\"mobilenet\")\n",
        "\n",
        "!zip -r mobilenet.zip mobilenet\n",
        "!zip -r conf.zip images\n",
        "\n",
        "files.download('mobilenet.zip') \n",
        "files.download('images.zip') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IOiBzx8FpDK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}