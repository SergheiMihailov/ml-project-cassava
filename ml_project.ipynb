{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ml-project",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergheiMihailov/ml-project-cassava/blob/main/ml_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPTZVE34UoKw",
        "outputId": "2abaf1ee-596a-457e-8cc9-e021c9bd2116"
      },
      "source": [
        "import gdown\n",
        "!gdown --id \"1NdsNtg7RpTESOKojFbG5vlJMyxbbnNfx\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NdsNtg7RpTESOKojFbG5vlJMyxbbnNfx\n",
            "To: /content/train_images.zip\n",
            "2.57GB [00:32, 79.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLQsPHlvVW3D"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/')\n",
        "!unzip -qq -o train_images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIiusKctVkKF"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "data = pd.read_csv('train.csv')\n",
        "f = open('label_num_to_disease_map.json')\n",
        "real_labels = json.load(f)\n",
        "real_labels = {int(k):v for k,v in real_labels.items()}\n",
        "data['class_name'] = data.label.map(real_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BozrJaLgVwxb",
        "outputId": "1977e44d-9e65-48ad-fb8d-3038b966511b"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "train_path = 'train_images/'\n",
        "train,val = train_test_split(data, test_size = 0.10, random_state = 42, stratify = data['class_name'])\n",
        "\n",
        "IMG_SIZE = 512\n",
        "SIZE = (IMG_SIZE,IMG_SIZE)\n",
        "CLASSES = 5\n",
        "BATCH_SIZE = 16\n",
        "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "dataget = ImageDataGenerator()\n",
        "\n",
        "train_set = dataget.flow_from_dataframe(train,\n",
        "                                directory = train_path,\n",
        "                                x_col = 'image_id',\n",
        "                                y_col = 'class_name',\n",
        "                                target_size = SIZE,\n",
        "                                color_mode=\"rgb\",\n",
        "                                class_mode = 'categorical',\n",
        "                                batch_size = BATCH_SIZE)\n",
        "\n",
        "val_set = dataget.flow_from_dataframe(val,\n",
        "                                directory = train_path,\n",
        "                                x_col = 'image_id',\n",
        "                                y_col = 'class_name',\n",
        "                                target_size = SIZE,\n",
        "                                color_mode=\"rgb\",\n",
        "                                class_mode = 'categorical',\n",
        "                                batch_size = BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19257 validated image filenames belonging to 5 classes.\n",
            "Found 2140 validated image filenames belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaPR5NkbWA7z",
        "outputId": "a28b5642-e8f6-43e3-8823-88cf7a9c247e"
      },
      "source": [
        "mobileNetV3Small = tf.keras.applications.MobileNetV3Small(\n",
        "    input_shape=INPUT_SHAPE, alpha=1, minimalistic=True, include_top=True,\n",
        "    weights=None, input_tensor=None, classes=5, pooling='avg',\n",
        "    dropout_rate=0, classifier_activation='softmax'\n",
        ")\n",
        "    \n",
        "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "inputs = tf.keras.applications.mobilenet_v3.preprocess_input(inputs)\n",
        "\n",
        "model = tf.keras.Model(inputs, mobileNetV3Small(inputs))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(\n",
        "        train_set,\n",
        "        steps_per_epoch=train_set.n // 32,\n",
        "        epochs=30,\n",
        "        validation_data=val_set,\n",
        "        validation_steps=val_set.n // 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "601/601 [==============================] - 174s 280ms/step - loss: 0.3671 - accuracy: 0.6136 - val_loss: 0.3942 - val_accuracy: 0.6288\n",
            "Epoch 2/30\n",
            "601/601 [==============================] - 166s 277ms/step - loss: 0.3115 - accuracy: 0.6397 - val_loss: 0.4245 - val_accuracy: 0.6326\n",
            "Epoch 3/30\n",
            "601/601 [==============================] - 166s 275ms/step - loss: 0.2953 - accuracy: 0.6570 - val_loss: 0.5692 - val_accuracy: 0.1117\n",
            "Epoch 4/30\n",
            "601/601 [==============================] - 165s 275ms/step - loss: 0.2676 - accuracy: 0.6966 - val_loss: 0.7991 - val_accuracy: 0.1117\n",
            "Epoch 5/30\n",
            "601/601 [==============================] - 165s 275ms/step - loss: 0.2534 - accuracy: 0.7198 - val_loss: 0.6540 - val_accuracy: 0.1184\n",
            "Epoch 6/30\n",
            "601/601 [==============================] - 165s 275ms/step - loss: 0.2475 - accuracy: 0.7246 - val_loss: 0.8373 - val_accuracy: 0.1629\n",
            "Epoch 7/30\n",
            "601/601 [==============================] - ETA: 0s - loss: 0.2345 - accuracy: 0.7416"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}