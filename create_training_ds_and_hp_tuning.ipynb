{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "create-training-dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergheiMihailov/ml-project-cassava/blob/main/create_training_ds_and_hp_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj2oWc2p5sCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61eba411-790b-4949-eef0-85221344fb85"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10kB 26.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 31.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 22.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 26.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 25.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 9.0MB/s \n",
            "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSSkhkyY_J1X"
      },
      "source": [
        "# Imports\n",
        "import gdown\n",
        "import os\n",
        "import json\n",
        "import csv   \n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import scipy.misc\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import tensorflow.keras.layers.experimental.preprocessing as keras_preproc\n",
        "import kerastuner as kt\n",
        "from pprint import pprint\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyDe7oML_J1e",
        "outputId": "43a2b4b2-c207-47bd-c047-73be82f80f80"
      },
      "source": [
        "# Download provided dataset\n",
        "!wget files.brainfriz.com/train_images.zip # secondary link for images\n",
        "!unzip -qq -o train_images.zip\n",
        "!gdown --id \"1xbEVK_NigW_5ngwKMHvuOTehYhT2v2WF\" # labels\n",
        "!gdown --id \"1SvI9dN2_25c2OlevwK4TjmzBNysjE_PO\" # label mapping"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-12 16:38:39--  http://files.brainfriz.com/train_images.zip\n",
            "Resolving files.brainfriz.com (files.brainfriz.com)... 138.201.201.196\n",
            "Connecting to files.brainfriz.com (files.brainfriz.com)|138.201.201.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://files.brainfriz.com/train_images.zip [following]\n",
            "--2021-03-12 16:38:40--  https://files.brainfriz.com/train_images.zip\n",
            "Connecting to files.brainfriz.com (files.brainfriz.com)|138.201.201.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2569658627 (2.4G) [application/zip]\n",
            "Saving to: ‘train_images.zip’\n",
            "\n",
            "train_images.zip    100%[===================>]   2.39G  31.3MB/s    in 79s     \n",
            "\n",
            "2021-03-12 16:40:00 (30.9 MB/s) - ‘train_images.zip’ saved [2569658627/2569658627]\n",
            "\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xbEVK_NigW_5ngwKMHvuOTehYhT2v2WF\n",
            "To: /content/train.csv\n",
            "100% 358k/358k [00:00<00:00, 5.72MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SvI9dN2_25c2OlevwK4TjmzBNysjE_PO\n",
            "To: /content/label_num_to_disease_map.json\n",
            "100% 172/172 [00:00<00:00, 147kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRv38K3LHvGQ"
      },
      "source": [
        "IMG_SIZE = 512\n",
        "\n",
        "def augment_image(img):\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
        "  img4d = tf.expand_dims(img, 0)\n",
        "  data_augmentation = tf.keras.Sequential([\n",
        "    keras_preproc.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "    keras_preproc.RandomRotation((0, 0.2)),\n",
        "    keras_preproc.RandomZoom((0,-0.3),\n",
        "  ])\n",
        "\n",
        "  aug_img_arr = data_augmentation(img4d)\n",
        "\n",
        "  aug_img = Image.fromarray(aug_img_arr.numpy()[0].astype(np.uint8))\n",
        "    \n",
        "  return aug_img\n",
        "\n",
        "def add_train_datapoint_cassava(image, image_id, label, train_images_dir_path, train_csv_path):\n",
        "    datapoint = dict({\n",
        "        'image_id': image_id,\n",
        "        'label': label,\n",
        "    })\n",
        "    \n",
        "    if not os.path.exists(train_images_dir_path):\n",
        "        os.makedirs(train_images_dir_path)\n",
        "      \n",
        "    image.save(train_images_dir_path + str(image_id)) # save\n",
        "  \n",
        "    with open(train_csv_path, 'a') as f:\n",
        "      writer = csv.DictWriter(f, ['image_id', 'label'])\n",
        "      writer.writerow(datapoint)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oGOjP8bCQEn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "57bc3cdf-1959-4c21-a9d4-d925db7c5ee1"
      },
      "source": [
        "def get_data_with_label(data, label):\n",
        "  return data.loc[data['label'] == label]\n",
        "\n",
        "original_data = pd.read_csv('train.csv')\n",
        "\n",
        "original_data.to_csv('orig_and_aug.csv')\n",
        "\n",
        "train_path = 'train_images/'\n",
        "\n",
        "unique_labels = set(original_data['label'])\n",
        "\n",
        "n_aug_for_balance = {}\n",
        "\n",
        "for label in unique_labels:\n",
        "  n_aug_for_balance[label] = len(original_data) - len(get_data_with_label(original_data, label))\n",
        "\n",
        "n_aug_for_balance_largest_class = min(n_aug_for_balance.values())\n",
        "\n",
        "for label in unique_labels:\n",
        "  n_aug_for_balance[label] -= n_aug_for_balance_largest_class\n",
        "\n",
        "!rm -rf orig_and_aug.csv orig_and_aug_train_images/\n",
        "\n",
        "for label in n_aug_for_balance.keys():\n",
        "  data_filtered_by_label = get_data_with_label(original_data, label)\n",
        "  for i in range(n_aug_for_balance[label]):\n",
        "    print(label, i)\n",
        "    datapoint_to_augment = data_filtered_by_label.iloc[i % len(data_filtered_by_label)]\n",
        "\n",
        "    image = cv2.imread(train_path + datapoint_to_augment['image_id'])\n",
        "    augmented_image = augment_image(image)\n",
        "    \n",
        "    add_train_datapoint_cassava(\n",
        "        image=augmented_image, \n",
        "        image_id='aug_'+str(label)+'_'+str(i)+'_'+datapoint_to_augment['image_id'], \n",
        "        label=datapoint_to_augment['label'],\n",
        "        train_images_dir_path='orig_and_aug_train_images/',\n",
        "        train_csv_path='orig_and_aug.csv'\n",
        "        )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0\n",
            "0 1\n",
            "0 2\n",
            "0 3\n",
            "0 4\n",
            "0 5\n",
            "0 6\n",
            "0 7\n",
            "0 8\n",
            "0 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8420e806f448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatapoint_to_augment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtrain_images_dir_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'orig_and_aug_train_images/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtrain_csv_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'orig_and_aug.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-7-3ed4c511d547>\u001b[0m in \u001b[0;36madd_train_datapoint_cassava\u001b[0;34m(image, image_id, label, train_images_dir_path, train_csv_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_dir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_dir_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/JpegImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0mbufsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAXBLOCK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexif\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jpeg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_to_pyfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoder error %d when writing image file\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qur8Em5p_J1f"
      },
      "source": [
        "\n",
        "def getEfficientNetB0():\n",
        "  return [\n",
        "      # architecture\n",
        "      tf.keras.applications.EfficientNetB0(\n",
        "        include_top=True, weights=None, input_tensor=None,\n",
        "        input_shape=INPUT_SHAPE, pooling=None, classes=N_CLASSES,\n",
        "        classifier_activation='softmax', drop_connect_rate=0.4\n",
        "      ),\n",
        "      # preprocess_input\n",
        "      tf.keras.applications.efficientnet.preprocess_input\n",
        "  ]\n",
        "\n",
        "def getResNet50V2(): \n",
        "  return [\n",
        "      # architecture \n",
        "      tf.keras.applications.ResNet50V2(\n",
        "        include_top=True, weights=None, input_tensor=None,\n",
        "        input_shape=INPUT_SHAPE, pooling=None, classes=N_CLASSES,\n",
        "        classifier_activation='softmax'\n",
        "      ),\n",
        "      # preprocess_input\n",
        "      tf.keras.applications.resnet_v2.preprocess_input\n",
        "  ]\n",
        "\n",
        "def getMobileNetV3Small(): \n",
        "  return [\n",
        "      # architecture\n",
        "      tf.keras.applications.MobileNetV3Small(\n",
        "        input_shape=INPUT_SHAPE, alpha=1, minimalistic=True, include_top=True,\n",
        "        weights=None, input_tensor=None, classes=5, pooling='avg',\n",
        "        dropout_rate=0, classifier_activation='softmax'\n",
        "      ),\n",
        "      # preprocess_input:\n",
        "      tf.keras.applications.mobilenet_v3.preprocess_input\n",
        "  ]\n",
        "\n",
        "IMG_SIZE = 512\n",
        "SIZE = (IMG_SIZE,IMG_SIZE)\n",
        "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "CLASSES = 5\n",
        "BATCH_SIZE = 16\n",
        "N_CV_SPLITS = 3"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afHUHNw3_J1f",
        "outputId": "40e8f16f-08b7-41bf-c620-ac710e97dc54"
      },
      "source": [
        "# Train with cross-validation\n",
        "data = pd.read_csv('train.csv')\n",
        "f = open('label_num_to_disease_map.json')\n",
        "real_labels = json.load(f)\n",
        "real_labels = {int(k):v for k,v in real_labels.items()}\n",
        "data['class_name'] = data.label.map(real_labels)\n",
        "\n",
        "train_path = 'train_images/'\n",
        "\n",
        "def model_builder(hp):\n",
        "  architecture, preprocess_input = getMobileNetV3Small()\n",
        "\n",
        "  input_layer = preprocess_input(tf.keras.layers.Input(shape=INPUT_SHAPE))\n",
        "\n",
        "  model = tf.keras.Model(input_layer, architecture(input_layer))\n",
        "  \n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  hp_label_smoothing = hp.Choice('label_smoothing', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.BinaryCrossentropy(label_smoothing=hp_label_smoothing),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='hyperparams'\n",
        "                     )\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "best_hps = None\n",
        "\n",
        "kfold = StratifiedKFold(n_splits = N_CV_SPLITS)\n",
        "cv_index = 0\n",
        "\n",
        "for train_indices, val_indices in kfold.split(data['image_id'], data['label']):\n",
        "  print('Training on cross-validation split '+str(cv_index))\n",
        "  train_ds = data.iloc[train_indices]\n",
        "  val_ds = data.iloc[val_indices]\n",
        "\n",
        "  imageDataGenerator = ImageDataGenerator()\n",
        "\n",
        "  train_set = imageDataGenerator.flow_from_dataframe(train_ds,\n",
        "                                  subset='training',\n",
        "                                  directory = train_path,\n",
        "                                  x_col = 'image_id',\n",
        "                                  y_col = 'class_name',\n",
        "                                  target_size = SIZE,\n",
        "                                  color_mode=\"rgb\",\n",
        "                                  class_mode = 'categorical',\n",
        "                                  batch_size = BATCH_SIZE)\n",
        "\n",
        "  val_set = imageDataGenerator.flow_from_dataframe(val_ds,\n",
        "                                  directory = train_path,\n",
        "                                  x_col = 'image_id',\n",
        "                                  y_col = 'class_name',\n",
        "                                  target_size = SIZE,\n",
        "                                  color_mode=\"rgb\",\n",
        "                                  class_mode = 'categorical',\n",
        "                                  batch_size = BATCH_SIZE)\n",
        "  \n",
        "  if cv_index == 0:\n",
        "    # Tune hyperparameters on first cross-validation (refactor later to use saved hps)\n",
        "    tuner.search(train_set, epochs=50, callbacks=[stop_early])\n",
        "\n",
        "    # Get the optimal hyperparameters\n",
        "    best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "    print(f\"\"\"\n",
        "    The hyperparameter search is complete. The optimal learning rate for the optimizer\n",
        "    is {best_hps.get('learning_rate')}.\n",
        "    \"\"\")\n",
        "\n",
        "  else:\n",
        "    model = tuner.hypermodel.build(best_hps)\n",
        "    history = model.fit(\n",
        "          train_set,\n",
        "          steps_per_epoch=train_set.n // 32,\n",
        "          epochs=30,\n",
        "          validation_data=val_set,\n",
        "          validation_steps=val_set.n // 32\n",
        "    )\n",
        "\n",
        "    val_acc_per_epoch = history.history['val_accuracy']\n",
        "    best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "    print('Best epoch: %d' % (best_epoch,))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project hyperparams/untitled_project/oracle.json\n",
            "Training on cross-validation split 0\n",
            "Found 14264 validated image filenames belonging to 5 classes.\n",
            "Found 7133 validated image filenames belonging to 5 classes.\n",
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "learning_rate     |0.0001            |?                 \n",
            "tuner/epochs      |2                 |?                 \n",
            "tuner/initial_e...|0                 |?                 \n",
            "tuner/bracket     |2                 |?                 \n",
            "tuner/round       |0                 |?                 \n",
            "\n",
            "Epoch 1/2\n",
            "892/892 [==============================] - 191s 210ms/step - loss: 0.3650 - accuracy: 0.6137\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 2/2\n",
            "124/892 [===>..........................] - ETA: 2:40 - loss: 0.2978 - accuracy: 0.6610"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgw-lYQg4sPx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}